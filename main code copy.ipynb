{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ae71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "API_KEY = 'YOUR_YOUTUBE_API_KEY_HERE'\n",
    "\n",
    "SEARCH_QUERIES = [\n",
    "    \"polusi udara jakarta\", \"kualitas udara jakarta\", \"cuaca jakarta\",\n",
    "    \"banjir jakarta\", \"debu jakarta\", \"asap jakarta\", \"kabut jakarta\",\n",
    "    \"hujan jakarta\", \"banjir jkt\", \"polusi jkt\"\n",
    "]\n",
    "\n",
    "VIDEO_IDS_MANUAL = [\n",
    "    \"Xmd_6ZXl6lI\",\"imlCPA5Vu2c\",\"OGw2Jhu4KlU\",\"fZU9Q1_GHLE\",\n",
    "    \"kJsBTQkZV0M\",\"Mp4hDSnpjQ4\",\"_41KtEUiZT8\",\"E4nuMUg96aM\",\n",
    "    \"frPoXlkkOXM\",\"zdhm5OuH5Qs\",\"52BE41TcHu4\",\"bnb8RHwortQ\"\n",
    "]\n",
    "\n",
    "COMMENT_KEYWORDS = [\n",
    "    \"banjir\",\"cuaca\",\"polusi\",\"polusi udara\",\"debu\",\"asap\",\"kabut\",\n",
    "    \"kualitas udara\",\"hujan\",\"angin\",\"kotor\",\"pabrik\",\"abu\",\"jkt\",\n",
    "    \"jakarta\",\"sungai\"\n",
    "]\n",
    "\n",
    "COMMENT_KEYWORDS = [k.lower() for k in COMMENT_KEYWORDS]\n",
    "\n",
    "\n",
    "def safe_get(url, params, max_retries=3, backoff=2):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=20)\n",
    "            if r.status_code == 200:\n",
    "                return r.json()\n",
    "            else:\n",
    "                print(f\"HTTP {r.status_code} - {r.text[:200]}\")\n",
    "                # if quota or forbidden, break early\n",
    "                if r.status_code in (403, 400):\n",
    "                    return {\"error\": f\"HTTP {r.status_code}\"}\n",
    "        except Exception as e:\n",
    "            print(\"Request error:\", e)\n",
    "        time.sleep(backoff * (attempt + 1))\n",
    "    return {\"error\": \"max retries\"}\n",
    "\n",
    "def search_videos(query, max_results=25):\n",
    "    url = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "    params = {\n",
    "        \"key\": API_KEY,\n",
    "        \"q\": query,\n",
    "        \"part\": \"id\",\n",
    "        \"maxResults\": max_results,\n",
    "        \"type\": \"video\"\n",
    "    }\n",
    "    data = safe_get(url, params)\n",
    "    ids = []\n",
    "    if \"items\" in data:\n",
    "        for it in data[\"items\"]:\n",
    "            vid = it.get(\"id\", {}).get(\"videoId\")\n",
    "            if vid:\n",
    "                ids.append(vid)\n",
    "    else:\n",
    "        print(\"Search error or no items for query:\", query, data.get(\"error\"))\n",
    "    return ids\n",
    "\n",
    "def scrape_comments_for_video(video_id):\n",
    "    url = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
    "    results = []\n",
    "    page_token = None\n",
    "    checked = 0\n",
    "    matched = 0\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"key\": API_KEY,\n",
    "            \"part\": \"snippet\",\n",
    "            \"videoId\": video_id,\n",
    "            \"maxResults\": 100,\n",
    "            \"textFormat\": \"plainText\"\n",
    "        }\n",
    "        if page_token:\n",
    "            params[\"pageToken\"] = page_token\n",
    "\n",
    "        data = safe_get(url, params)\n",
    "        if \"error\" in data:\n",
    "            print(\"API error while fetching comments for\", video_id, data.get(\"error\"))\n",
    "            break\n",
    "\n",
    "        items = data.get(\"items\", [])\n",
    "        if not items and page_token is None:\n",
    "            print(f\"-> No commentThreads returned for video {video_id} (comments may be disabled or none).\")\n",
    "            break\n",
    "\n",
    "        for it in items:\n",
    "            try:\n",
    "                c = it[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            except Exception:\n",
    "                continue\n",
    "            checked += 1\n",
    "            text = c.get(\"textDisplay\", \"\")\n",
    "            text_l = text.lower()\n",
    "            published = c.get(\"publishedAt\")\n",
    "\n",
    "            dt = None\n",
    "            if published:\n",
    "                try:\n",
    "                    dt = datetime.fromisoformat(published.replace(\"Z\", \"+00:00\"))\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        dt = datetime.strptime(published, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                    except Exception:\n",
    "                        dt = None\n",
    "\n",
    "            if dt and dt.year == 2023 and any(kw in text_l for kw in COMMENT_KEYWORDS):\n",
    "                matched += 1\n",
    "                results.append({\n",
    "                    \"tanggal\": dt.strftime(\"%Y-%m-%d\"),\n",
    "                    \"komentar\": text,\n",
    "                    \"video_id\": video_id\n",
    "                })\n",
    "\n",
    "        page_token = data.get(\"nextPageToken\")\n",
    "        if not page_token:\n",
    "            break\n",
    "\n",
    "    return results, checked, matched\n",
    "\n",
    "video_ids = set(VIDEO_IDS_MANUAL)\n",
    "\n",
    "print(\"Searching videos from queries...\")\n",
    "for q in SEARCH_QUERIES:\n",
    "    found = search_videos(q, max_results=25)\n",
    "    for v in found:\n",
    "        video_ids.add(v)\n",
    "\n",
    "video_ids = list(video_ids)\n",
    "print(\"Total videos to check:\", len(video_ids))\n",
    "\n",
    "all_rows = []\n",
    "summary = []\n",
    "\n",
    "for vid in video_ids:\n",
    "    print(\"\\n--- Processing video:\", vid)\n",
    "    rows, checked, matched = scrape_comments_for_video(vid)\n",
    "    print(f\"Checked comments: {checked}, Matched: {matched} for video {vid}\")\n",
    "    all_rows.extend(rows)\n",
    "    summary.append({\"video_id\": vid, \"checked\": checked, \"matched\": matched})\n",
    "\n",
    "outfile = \"data/komentar_jakarta_2023_debug.csv\"\n",
    "if all_rows:\n",
    "    with open(outfile, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"tanggal\", \"komentar\", \"video_id\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_rows)\n",
    "    print(f\"\\nSelesai. Disimpan: {outfile}. Total matched rows: {len(all_rows)}\")\n",
    "else:\n",
    "    print(\"\\nTidak ditemukan komentar yang cocok di semua video (hasil matched = 0).\")\n",
    "    print(\"Ringkasan per video (checked, matched):\")\n",
    "    for s in summary:\n",
    "        print(f\" - {s['video_id']}: checked={s['checked']}, matched={s['matched']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a6651",
   "metadata": {},
   "source": [
    "SCRAPING COMENTAR YOUTUBE TENTANG RESPON PUBLIK TERHADAP CUACA DAN KUALITAS UDARA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf8f20",
   "metadata": {},
   "source": [
    "Cleaning hasil scraping sentimen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = pd.read_csv(\"data/komentar_jakarta_2023_debug.csv\")\n",
    "\n",
    "data = data.dropna(how=\"all\")\n",
    "\n",
    "def bersihkan_komentar(teks):\n",
    "    if pd.isna(teks):\n",
    "        return \"\"\n",
    "    teks = str(teks).strip()\n",
    "\n",
    "    teks = re.sub(r\"[^a-zA-Z0-9.,!?()/%\\- ]+\", \" \", teks)\n",
    "\n",
    "    teks = re.sub(r\"\\s+\", \" \", teks)\n",
    "\n",
    "    return teks.strip()\n",
    "\n",
    "\n",
    "data[\"komentar\"] = data[\"komentar\"].apply(bersihkan_komentar)\n",
    "\n",
    "data = data[data[\"komentar\"] != \"\"]\n",
    "\n",
    "data = data.drop_duplicates(subset=[\"tanggal\", \"komentar\"])\n",
    "\n",
    "kelompok_tanggal = data.groupby(\"tanggal\")[\"komentar\"].apply(list).reset_index()\n",
    "\n",
    "\n",
    "maksimal_isi = kelompok_tanggal[\"komentar\"].apply(len).max()\n",
    "\n",
    "for i in range(maksimal_isi):\n",
    "    kelompok_tanggal[f\"sentimen_{i+1}\"] = kelompok_tanggal[\"komentar\"].apply(\n",
    "        lambda daftar: daftar[i] if i < len(daftar) else \"\"\n",
    "    )\n",
    "\n",
    "kelompok_tanggal = kelompok_tanggal.drop(columns=[\"komentar\"])\n",
    "display(kelompok_tanggal.head())\n",
    "\n",
    "\n",
    "kelompok_tanggal.to_csv(\"data_clean/data_sentimen_bersih.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4f5a7",
   "metadata": {},
   "source": [
    "CLEANING CUACA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc09f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('data/dataset_prediksi_cuaca.xlsx')\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.applymap(lambda x: str(x).strip() if isinstance(x, str) else x)\n",
    "df.drop(columns=['Lokasi'], inplace=True)\n",
    "\n",
    "kolom_numerik = [\n",
    "    'Suhu Maks (deg of C)', 'Suhu Min (deg of C)', 'Kelembaban (%)',\n",
    "    'Kecepatan Angin (km/jam)', 'Arah Angin (deg)', 'Tekanan Udara (hPa)',\n",
    "    'Tutupan Awan (%)', 'Curah Hujan Hari Ini (mm)', 'Curah Hujan Besok (mm)'\n",
    "]\n",
    "\n",
    "mapping_cuaca = {\n",
    "    'Cerah Berawan':2,\n",
    "    'Hujan Ringan':1,\n",
    "    'Cerah':0,\n",
    "    'Hujan Sedang':-1,\n",
    "    'Hujan Lebat':-2\n",
    "}\n",
    "\n",
    "\n",
    "for kolom in kolom_numerik:\n",
    "    df[kolom] = df[kolom].astype(str).str.replace(',', '.', regex=False)\n",
    "    df[kolom] = pd.to_numeric(df[kolom], errors='coerce')\n",
    "    df[kolom] = df[kolom].interpolate(method='linear')\n",
    "    df[kolom] = df[kolom].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "df['Tanggal'] = pd.to_datetime(df['Tanggal'], errors='coerce')\n",
    "df_2023 = df[df['Tanggal'].dt.year == 2023]\n",
    "df_2023 = df_2023.drop_duplicates()\n",
    "df_2023 = df_2023.dropna(subset=['Tanggal'])\n",
    "\n",
    "\n",
    "df_2023['Cuaca Hari Ini'] = pd.to_numeric(df_2023['Cuaca Hari Ini'].replace(mapping_cuaca))\n",
    "df_2023['Cuaca Besok'] = pd.to_numeric(df_2023['Cuaca Besok'].replace(mapping_cuaca))\n",
    "df_2023.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_2023.to_csv(\"data_clean/data_cuaca_jakarta_2023_bersih.csv\", index=False)\n",
    "\n",
    "display(df_2023.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065dfc09",
   "metadata": {},
   "source": [
    "CLEANING DATA KUALITAS UDARA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = pd.read_csv(\"data/ispu_dki4.csv\")\n",
    "\n",
    "data.columns = data.columns.str.strip().str.lower()\n",
    "\n",
    "mapping_udara = {\n",
    "'TIDAK ADA DATA':0,\n",
    "'SANGAT TIDAK SEHAT':0,\n",
    "'TIDAK SEHAT':1,\n",
    "'SEDANG':2,\n",
    "'BAIK':3\n",
    "}\n",
    "data.drop(columns=['stasiun', 'critical', 'max'], inplace=True)\n",
    "\n",
    "\n",
    "kolom_angka = [\"pm25\",\"pm10\",\"so2\",\"co\",\"o3\",\"no2\"]\n",
    "\n",
    "for kolom in kolom_angka:\n",
    "    data[kolom] = (\n",
    "        data[kolom]\n",
    "        .astype(str)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "        .str.strip()\n",
    "    )\n",
    "    data[kolom] = pd.to_numeric(data[kolom], errors=\"coerce\")\n",
    "    \n",
    "    \n",
    "    data[kolom] = data[kolom].interpolate(method='linear')\n",
    "    data[kolom] = data[kolom].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "data[\"tanggal\"] = pd.to_datetime(data[\"tanggal\"], errors=\"coerce\")\n",
    "data = data[data['tanggal'].dt.year == 2023]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data['categori'] = pd.to_numeric(data['categori'].replace(mapping_udara))\n",
    "\n",
    "data = data.dropna(subset=[\"tanggal\"])\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "display(data.head())\n",
    "data.to_csv(\"data_clean/kualitas_udara_jakarta_2023_bersih.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7314d",
   "metadata": {},
   "source": [
    "INTEGRASI BERDASARKAN TANGGAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_sentimen = pd.read_csv(\"data_clean/data_sentimen_bersih.csv\")\n",
    "data_cuaca = pd.read_csv(\"data_clean/data_cuaca_jakarta_2023_bersih.csv\")\n",
    "data_udara = pd.read_csv(\"data_clean/kualitas_udara_jakarta_2023_bersih.csv\")\n",
    "\n",
    "\n",
    "data_sentimen[\"tanggal\"] = pd.to_datetime(data_sentimen[\"tanggal\"], errors=\"coerce\")\n",
    "\n",
    "data_cuaca[\"tanggal\"] = pd.to_datetime(data_cuaca[\"Tanggal\"], errors=\"coerce\")\n",
    "\n",
    "data_udara[\"tanggal\"] = pd.to_datetime(data_udara[\"tanggal\"], errors=\"coerce\")\n",
    "\n",
    "data_cuaca = data_cuaca.drop(columns=[\"Tanggal\"])\n",
    "\n",
    "gabung_cuaca_udara = pd.merge(\n",
    "    data_cuaca,\n",
    "    data_udara,\n",
    "    on=\"tanggal\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "gabungan_akhir = pd.merge(\n",
    "    gabung_cuaca_udara,\n",
    "    data_sentimen,\n",
    "    on=\"tanggal\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "if \"tanggal\" not in gabungan_akhir.columns:\n",
    "    raise ValueError(\"Kolom 'tanggal' hilang. Periksa merge.\")\n",
    "\n",
    "gabungan_akhir = gabungan_akhir.sort_values(\"tanggal\")\n",
    "\n",
    "kolom_akhir = [\"tanggal\"] + [col for col in gabungan_akhir.columns if col != \"tanggal\"]\n",
    "gabungan_akhir = gabungan_akhir[kolom_akhir]\n",
    "\n",
    "sentimen_cols = [col for col in gabungan_akhir.columns if col.startswith(\"sentimen_\")]\n",
    "gabungan_akhir[\"total_sentimen\"] = gabungan_akhir[sentimen_cols].count(axis=1)  \n",
    "\n",
    "for kol in [\"unnamed: 0\", \"Unnamed: 0\"]:\n",
    "    if kol in gabungan_akhir.columns:\n",
    "        gabungan_akhir = gabungan_akhir.drop(columns=[kol])\n",
    "\n",
    "gabungan_akhir.to_csv(\"data_clean/integrasi_cuaca_udara_sentimen_2023.csv\", index=False)\n",
    "\n",
    "\n",
    "display(gabungan_akhir.head())\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "\n",
    "print(\"\\nJumlah baris:\", len(gabungan_akhir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375fb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('integrasi_cuaca_udara_sentimen_2023.csv')\n",
    "\n",
    "numeric_cols = [\n",
    "    'Suhu Maks (deg of C)',\n",
    "    'Suhu Min (deg of C)',\n",
    "    'Kelembaban (%)',\n",
    "    'Kecepatan Angin (km/jam)',\n",
    "    'Tekanan Udara (hPa)',\n",
    "    'Tutupan Awan (%)',\n",
    "    'Curah Hujan Hari Ini (mm)',\n",
    "    'pm25', 'pm10', 'so2', 'co', 'o3', 'no2',\n",
    "    'total_sentimen'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "display(df[numeric_cols].describe())\n",
    "\n",
    "df[numeric_cols].hist(bins=20, figsize=(15, 12))\n",
    "plt.suptitle('Distribusi Variabel Numerik')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "suhu_maks_norm = (df['Suhu Maks (deg of C)'] - df['Suhu Maks (deg of C)'].min()) / (df['Suhu Maks (deg of C)'].max() - df['Suhu Maks (deg of C)'].min())\n",
    "pm25_norm = (df['pm25'] - df['pm25'].min()) / (df['pm25'].max() - df['pm25'].min())\n",
    "total_sentimen_norm = (df['total_sentimen'] - df['total_sentimen'].min()) / (df['total_sentimen'].max() - df['total_sentimen'].min())\n",
    "\n",
    "plt.plot(df['tanggal'], suhu_maks_norm, label='Suhu Maks (normalized)', alpha=0.7)\n",
    "plt.plot(df['tanggal'], pm25_norm, label='PM2.5 (normalized)', alpha=0.7)\n",
    "plt.plot(df['tanggal'], total_sentimen_norm, label='Total Sentimen/Komentar (normalized)', alpha=0.7)\n",
    "plt.title('Tren Harian: Suhu Maks, PM2.5, dan Volume Komentar')\n",
    "plt.xlabel('Tanggal')\n",
    "plt.ylabel('Nilai')\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))  # tiap minggu\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outlier_iqr(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "\n",
    "\n",
    "outlier_suhu = detect_outlier_iqr(df, 'Suhu Maks (deg of C)')\n",
    "print(\"Outlier Suhu Maks:\")\n",
    "display(outlier_suhu[['tanggal', 'Suhu Maks (deg of C)']])\n",
    "\n",
    "\n",
    "outlier_hujan = detect_outlier_iqr(df, 'Curah Hujan Hari Ini (mm)')\n",
    "print(\"Outlier Curah Hujan:\")\n",
    "display(outlier_hujan[['tanggal', 'Curah Hujan Hari Ini (mm)']])\n",
    "\n",
    "\n",
    "outlier_pm25 = detect_outlier_iqr(df, 'pm25')\n",
    "print(\"Outlier PM2.5:\")\n",
    "display(outlier_pm25[['tanggal', 'pm25']])\n",
    "\n",
    "\n",
    "outlier_sentimen = detect_outlier_iqr(df, 'total_sentimen')\n",
    "print(\"Outlier Komentar/Sentimen:\")\n",
    "display(outlier_sentimen[['tanggal', 'total_sentimen']])\n",
    "\n",
    "anomaly_merge = outlier_sentimen.merge(\n",
    "    df[['tanggal', 'Suhu Maks (deg of C)', 'Curah Hujan Hari Ini (mm)', 'pm25']],\n",
    "    on='tanggal', how='left'\n",
    ")\n",
    "print(\"Merge Outlier Sentimen dan Info Lingkungan:\")\n",
    "display(anomaly_merge)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df['tanggal'], df['total_sentimen'], label='Total Sentimen')\n",
    "plt.scatter(outlier_sentimen['tanggal'], outlier_sentimen['total_sentimen'], color='red', label='Outlier Sentimen')\n",
    "plt.title('Ledakan Volume Komentar (Outlier)')\n",
    "plt.ylabel('Total Komentar/Sentimen')\n",
    "plt.xlabel('Tanggal')\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))  # tiap minggu\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "sentimen_norm = (df['total_sentimen'] - df['total_sentimen'].min()) / (df['total_sentimen'].max() - df['total_sentimen'].min())\n",
    "pm25_norm = (df['pm25'] - df['pm25'].min()) / (df['pm25'].max() - df['pm25'].min())\n",
    "\n",
    "plt.plot(df['tanggal'], sentimen_norm, label='Volume Sentimen (normalized)')\n",
    "plt.plot(df['tanggal'], pm25_norm, label='PM2.5 (normalized)', alpha=0.7)\n",
    "plt.title('Tren Volume Sentimen dan PM2.5 Harian (Normalized)')\n",
    "plt.xlabel('Tanggal')\n",
    "plt.ylabel('Nilai Normalized (0-1)')\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))  # tiap minggu\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b000d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_final = pd.read_csv('integrasi_cuaca_udara_sentimen_2023.csv')  # Ganti dengan nama file aslinya\n",
    "\n",
    "\n",
    "kolom_numerik = df_final.select_dtypes(include=\"number\")\n",
    "corr = kolom_numerik.corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "plt.imshow(corr, cmap=\"viridis\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.title(\"Heatmap Korelasi dengan Nilai Angka\")\n",
    "\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(len(corr.columns)):\n",
    "        value = corr.iloc[i, j]\n",
    "        plt.text(j, i, f\"{value:.2f}\", ha='center', va='center', color='white', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df['tanggal'] = pd.to_datetime(df['tanggal'])\n",
    "df['bulan'] = df['tanggal'].dt.month\n",
    "\n",
    "\n",
    "fitur = ['Suhu Maks (deg of C)', 'Curah Hujan Hari Ini (mm)', 'pm25', 'total_sentimen']\n",
    "\n",
    "# (rata-rata per bulan)\n",
    "bulanan = df.groupby('bulan')[fitur].mean()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for col in fitur:\n",
    "    plt.plot(bulanan.index, bulanan[col], marker='o', label=col)\n",
    "plt.legend()\n",
    "plt.title('Trend Bulanan Cuaca, Polusi, dan Volume Sentimen')\n",
    "plt.xlabel('Bulan')\n",
    "plt.ylabel('Rata-rata')\n",
    "plt.xticks(range(1,13))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(12,8))\n",
    "for i, col in enumerate(fitur, 1):\n",
    "    plt.subplot(2,2,i)\n",
    "    sns.boxplot(x='bulan', y=col, data=df, palette='tab20')\n",
    "    plt.title(f'Persebaran {col} per Bulan')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Statistik Bulanan:\")\n",
    "print(bulanan)\n",
    "\n",
    "# Jika ingin analisis musiman (berdasarkan aturan lokal), misal musim hujan (Nov-Apr), kemarau (Mei-Okt):\n",
    "df['musim'] = df['bulan'].apply(lambda x: 'Hujan' if x in [11,12,1,2,3,4] else 'Kemarau')\n",
    "musiman = df.groupby('musim')[fitur].mean()\n",
    "print(\"\\nStatistik Musiman:\")\n",
    "print(musiman)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kolom_numerik.max()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
